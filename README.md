# Biomedical Data Scraper Platform

> A scalable, AI-powered, production-ready data scraping platform for biomedical research databases. Built with Apache Airflow + Scrapy.

## ğŸŒŸ Overview

This platform is designed as a **universal, extensible data acquisition infrastructure** that can efficiently scrape data from multiple biomedical research platforms. It separates core infrastructure from platform-specific adapters, enabling rapid integration of new data sources with minimal development effort.

### Key Features

- **ğŸ”§ Modular Architecture**: Separation of core infrastructure and platform adapters
- **ğŸš€ Scalable Design**: Distributed task execution with Redis and Celery
- **ğŸ¤– AI-Assisted Development**: GPT-4 powered code generation for new adapters
- **ğŸ” Unified Authentication**: Centralized credential management for all platforms
- **ğŸ“Š Comprehensive Monitoring**: Real-time dashboards and alerting system
- **ğŸ”„ Auto-Recovery**: Intelligent retry mechanisms and error handling
- **ğŸ“¦ Data Quality Assurance**: Built-in validation and deduplication
- **ğŸ³ Docker Ready**: Complete containerization for easy deployment

## ğŸ“‹ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Apache Airflow                           â”‚
â”‚              (Orchestration & Scheduling)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Core Infrastructure                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚   Auth Mgr   â”‚  â”‚  Data Pipelineâ”‚  â”‚   Monitor    â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Platform Adapters (Scrapy Spiders)             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  BioLINCC    â”‚  â”‚   OpenICPSR  â”‚  â”‚   YODA       â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Data Storage Layer                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  PostgreSQL  â”‚  â”‚    MinIO     â”‚  â”‚    Redis     â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

We provide two running modes: **Local Direct Execution** (no Docker required, suitable for quick testing and development) and **Docker Containerized Execution** (recommended for production environments).

### Local Direct Execution (No Docker)

1. **Clone the repository**
```bash
git clone https://github.com/Miniaspace/biomedical-data-scraper-platform.git
cd biomedical-data-scraper-platform
```

2. **Install dependencies**
```bash
# Install dependencies for local execution
pip install -r requirements-local.txt
```

3. **Run the scraper**
```bash
# List all available platforms
python run_local.py --list

# Run a single platform (e.g., Kids First)
python run_local.py --platform kidsfirst

# Run all enabled platforms
python run_local.py --platform all
```

For a detailed guide, please see [QUICKSTART.md](QUICKSTART.md).

### Docker Containerized Execution (Recommended for Production)

1. **Clone the repository**
```bash
git clone https://github.com/Miniaspace/biomedical-data-scraper-platform.git
cd biomedical-data-scraper-platform
```

2. **Configure environment variables**
```bash
cp .env.example .env
# Edit .env with your configurations
```

3. **Start the platform**
```bash
docker-compose up -d
```

4. **Access Airflow UI**
```
URL: http://localhost:8080
Username: airflow
Password: airflow
```

## ğŸ“š Directory Structure

```
biomedical-data-scraper-platform/
â”œâ”€â”€ dags/                      # Airflow DAG definitions
â”‚   â”œâ”€â”€ platform_dag_factory.py    # Dynamic DAG generator
â”‚   â””â”€â”€ example_platform_dag.py    # Example DAG
â”œâ”€â”€ spiders/                   # Scrapy spiders (Platform Adapters)
â”‚   â”œâ”€â”€ base_spider.py             # Base spider template
â”‚   â”œâ”€â”€ biolincc_spider.py         # BioLINCC adapter
â”‚   â””â”€â”€ openicpsr_spider.py        # OpenICPSR adapter
â”œâ”€â”€ common/                    # Core infrastructure modules
â”‚   â”œâ”€â”€ auth/                      # Authentication management
â”‚   â”œâ”€â”€ pipeline/                  # Data processing pipelines
â”‚   â”œâ”€â”€ monitor/                   # Monitoring and alerting
â”‚   â””â”€â”€ utils/                     # Utility functions
â”œâ”€â”€ config/                    # Configuration files
â”‚   â”œâ”€â”€ platforms.yaml             # Platform configurations
â”‚   â”œâ”€â”€ credentials.yaml.example   # Credential template
â”‚   â””â”€â”€ airflow.cfg                # Airflow configuration
â”œâ”€â”€ scripts/                   # Deployment and utility scripts
â”‚   â”œâ”€â”€ setup.sh                   # Initial setup script
â”‚   â””â”€â”€ add_platform.py            # Add new platform script
â”œâ”€â”€ tests/                     # Unit and integration tests
â”œâ”€â”€ docs/                      # Documentation
â”‚   â”œâ”€â”€ architecture.md            # Architecture design
â”‚   â”œâ”€â”€ adding_new_platform.md     # Guide for adding platforms
â”‚   â””â”€â”€ deployment.md              # Deployment guide
â”œâ”€â”€ data/                      # Data storage (gitignored)
â”‚   â”œâ”€â”€ raw/                       # Raw scraped data
â”‚   â”œâ”€â”€ processed/                 # Processed data
â”‚   â””â”€â”€ logs/                      # Application logs
â”œâ”€â”€ docker-compose.yml         # Docker orchestration
â”œâ”€â”€ Dockerfile                 # Custom Airflow image
â”œâ”€â”€ requirements.txt           # Python dependencies
â””â”€â”€ README.md                  # This file
```

## ğŸ”§ Adding a New Platform

Adding a new data source takes only **3 simple steps**:

### Step 1: Create Spider Adapter

```python
# spiders/new_platform_spider.py
from common.base_spider import BaseSpider

class NewPlatformSpider(BaseSpider):
    name = 'new_platform'
    
    def parse_list_page(self, response):
        # Extract detail page links
        pass
    
    def parse_detail_page(self, response):
        # Extract target data fields
        pass
```

### Step 2: Add Configuration

```yaml
# config/platforms.yaml
new_platform:
  name: "New Platform"
  base_url: "https://new-platform.com"
  spider_class: "NewPlatformSpider"
  schedule: "0 2 * * *"  # Daily at 2 AM
```

### Step 3: Deploy

```bash
python scripts/add_platform.py new_platform
```

That's it! The platform will automatically create a DAG and start scraping.

## ğŸ“– Documentation

- [Architecture Design](docs/architecture.md) - Detailed system architecture
- [Adding New Platforms](docs/adding_new_platform.md) - Step-by-step guide
- [Deployment Guide](docs/deployment.md) - Production deployment
- [API Reference](docs/api_reference.md) - Core module APIs
- [Troubleshooting](docs/troubleshooting.md) - Common issues and solutions

## ğŸ›  Technology Stack

| Component | Technology |
|-----------|-----------|
| **Orchestration** | Apache Airflow 2.8+ |
| **Scraping** | Scrapy 2.11+ |
| **Task Queue** | Redis + Celery |
| **Database** | PostgreSQL 15+ |
| **Object Storage** | MinIO |
| **Containerization** | Docker + Docker Compose |
| **Monitoring** | Prometheus + Grafana |
| **Dynamic Pages** | Playwright |
| **AI Assistant** | OpenAI GPT-4 |

## ğŸ“Š Current Platform Coverage

This platform currently supports **75 biomedical research databases**, including:

- BioLINCC (NHLBI)
- OpenICPSR
- YODA Project
- Vivli
- NCBI dbGaP
- And 70+ more...

See [PLATFORMS.md](docs/PLATFORMS.md) for the complete list.

## ğŸ¤ Contributing

Contributions are welcome! Please read our [Contributing Guide](CONTRIBUTING.md) for details.

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Built with [Apache Airflow](https://airflow.apache.org/)
- Powered by [Scrapy](https://scrapy.org/)
- Inspired by the open-source community

## ğŸ“§ Contact

For questions or support, please open an issue on GitHub.

---

**Made with â¤ï¸ for the biomedical research community**
